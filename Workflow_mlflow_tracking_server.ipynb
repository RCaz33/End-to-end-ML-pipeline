{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b0b15e",
   "metadata": {},
   "source": [
    "https://mlflow.org/docs/latest/ml/tracking/#tracking_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45484232",
   "metadata": {},
   "source": [
    "# Mimick running mlflow server \n",
    "* experiemnt data in PostGres\n",
    "* artifacts on S3 bucket (mimicked by Minio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94266f",
   "metadata": {},
   "source": [
    "1. install necessary librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815161e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: psycopg2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (2.9.10)\n",
      "Requirement already satisfied: boto3 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (1.40.39)\n",
      "Requirement already satisfied: Flask<4 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (2.3.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (0.34.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: fastapi<1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (0.115.7)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (3.1.43)\n",
      "Requirement already satisfied: graphene<4 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (22.0.0)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (8.5.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (2.1.3)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (1.31.1)\n",
      "Requirement already satisfied: packaging<26 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (24.1)\n",
      "Requirement already satisfied: pandas<3 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (5.28.2)\n",
      "Requirement already satisfied: pyarrow<22,>=4.0.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn<2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (4.12.2)\n",
      "Requirement already satisfied: uvicorn<1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from mlflow) (0.34.0)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.39 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from boto3) (1.40.39)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: Mako in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.39->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.39->boto3) (2.2.3)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow) (2.35.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from fastapi<1->mlflow) (0.45.3)\n",
      "Requirement already satisfied: Werkzeug>=2.3.7 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from Flask<4->mlflow) (2.3.8)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from graphene<4->mlflow) (3.1.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from graphene<4->mlflow) (3.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow) (3.20.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.52b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from uvicorn<1->mlflow) (0.14.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.39->boto3) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from starlette<0.46.0,>=0.40.0->fastapi<1->mlflow) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi<1->mlflow) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi<1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing dependencies of ipython-genutils: [Errno 2] No such file or directory: '/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/ipython_genutils-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of jupyter-highlight-selected-word: [Errno 2] No such file or directory: '/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/jupyter_highlight_selected_word-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install mlflow psycopg2 boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4589c91",
   "metadata": {},
   "source": [
    "2. setup env variable for mlflow to use S3 mimick build with docker\n",
    "\n",
    "* Key Differences: FakeS3 / AWS S3\n",
    "\n",
    "| Component       | MinIO (Local)                                | Real S3 (AWS)                  |\n",
    "|-----------------|----------------------------------------------|--------------------------------|\n",
    "| **Endpoint**    | `MLFLOW_S3_ENDPOINT_URL=http://localhost:9000` | Not needed (uses AWS default)  |\n",
    "| **Access Key**  | `AWS_ACCESS_KEY_ID=minio_user`               | `AWS_ACCESS_KEY_ID=your_aws_key` |\n",
    "| **Secret Key**  | `AWS_SECRET_ACCESS_KEY=minio_password`       | `AWS_SECRET_ACCESS_KEY=your_aws_secret` |\n",
    "| **Region**      | Any (MinIO ignores it)                       | Must be your actual AWS region |\n",
    "| **Buckets**     | `s3://s3mimick` (created by `mc` command)    | `s3://your-existing-bucket`    |\n",
    "| **Docker Services** | PostgreSQL + MinIO + `mc`                | PostgreSQL only                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# necessary because bash doesnt necessarely knows where is .env for mlflow to connect to AWS\n",
    "export AWS_ACCESS_KEY_ID=minio_user\n",
    "export AWS_SECRET_ACCESS_KEY=minio_password\n",
    "export AWS_DEFAULT_REGION=us-east-1\n",
    "# only necessary if using minio , AWS set it up automatically\n",
    "export AWS_ENDPOINT_URL=http://localhost:9000\n",
    "# for security, restricting model to be logged to Specific S3 Buckets using Regex expression\n",
    "export MLFLOW_CREATE_MODEL_VERSION_SOURCE_VALIDATION_REGEX=\"^s3://(production-models|staging-models)/.*$\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397af7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minio_user\n",
      "minio_password\n",
      "us-east-1\n",
      "http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "echo ${AWS_ACCESS_KEY_ID}\n",
    "echo ${AWS_SECRET_ACCESS_KEY}\n",
    "echo ${AWS_DEFAULT_REGION}\n",
    "echo ${AWS_ENDPOINT_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db444d",
   "metadata": {},
   "source": [
    "3. set-up remote data stores (conf. in .yaml ; postgres for metatdata & minio for artifacts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee8305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container end-to-end-ml-pipeline-minio-1  Running\n",
      " Container end-to-end-ml-pipeline-postgres-1  Running\n",
      " Container end-to-end-ml-pipeline-minio-create-s3_mimick-1  Recreate\n",
      " Container end-to-end-ml-pipeline-minio-create-s3_mimick-1  Recreated\n",
      " Container end-to-end-ml-pipeline-minio-1  Waiting\n",
      " Container end-to-end-ml-pipeline-minio-1  Healthy\n",
      " Container end-to-end-ml-pipeline-minio-create-s3_mimick-1  Starting\n",
      " Container end-to-end-ml-pipeline-minio-create-s3_mimick-1  Started\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "# dockerfile i sable to use the .env file\n",
    "docker compose -f compose_mimick_S3.yaml --env-file .env up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4079b0",
   "metadata": {},
   "source": [
    "4. start the mlflow server BUCKET location as artifact destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f6c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 18:32:13 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/09/28 18:32:13 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume transactional DDL.\n",
      "2025/09/28 18:32:13 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/09/28 18:32:13 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "# release the port for mlflow (error of port used not seen from notebook)\n",
    "lsof -ti:5005 | xargs kill -9\n",
    "\n",
    "# start mlflow server\n",
    "mlflow server \\\n",
    "    --backend-store-uri postgresql://${MIMICK_POSTGRES_USER}:${MIMICK_POSTGRES_PASSWORD}@localhost:5432/${MIMICK_POSTGRES_DATABASE} \\\n",
    "        --artifacts-destination ${MIMICK_S3_BUCKET} \\\n",
    "            --host 0.0.0.0 --port 5005  \\\n",
    "                --gunicorn-opts \"--daemon\"  \n",
    "# gunicorn needed to run following cells in a notebook              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo ${MIMICK_S3_BUCKET}\n",
    "echo ${MIMICK_POSTGRES_USER}\n",
    "echo ${MIMICK_POSTGRES_PASSWORD}\n",
    "echo ${MIMICK_POSTGRES_DATABASE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a601132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify mlflow is up and running\n",
    "import requests\n",
    "requests.get(\"http://localhost:5002/health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0fe32",
   "metadata": {},
   "source": [
    "5. log to mlflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2e16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if start from here make sure AWS environ variables are declared for mlflow to be granted access\n",
    "# import os\n",
    "# os.environ['AWS_ACCESS_KEY_ID'] = \"minio_user\"\n",
    "# os.environ['AWS_SECRET_ACCESS_KEY'] = \"minio_password\" \n",
    "# os.environ['AWS_DEFAULT_REGION'] = \"us-east-1\"\n",
    "# os.environ['AWS_ENDPOINT_URL'] = \"http://localhost:9000\"\n",
    "\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5002\")\n",
    "# real use case would point to the actual mlflow running server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d4c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5005\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "echo ${MLFLOW_TRACKING_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba440ebb",
   "metadata": {},
   "source": [
    "6. send logs to postgres / artifacts to s3://minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74fc391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 20:24:59 INFO mlflow.tracking.fluent: Experiment with name 'Test loads on postgres & s3 bucket' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run nosy-stork-949 at: http://localhost:5002/#/experiments/1/runs/e6c41562e1a446e091ea5448a6abb367\n",
      "üß™ View experiment at: http://localhost:5002/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# test good connection to postgres and S3 storage\n",
    "mlflow.set_experiment(\"Test loads on postgres & s3 bucket\")\n",
    "with mlflow.start_run():\n",
    "     mlflow.log_params({\n",
    "            \"search_space_max_iter\": f\"arange(100, 1000, 100)\"\n",
    "        })\n",
    "     mlflow.log_artifact(\"./requirements.txt\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648cf20",
   "metadata": {},
   "source": [
    "# Load Experiment on Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9efd7e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV with n_iter=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging best parameters and cross-validation score...\n",
      "Logging best estimator model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Best-logreg-from-RandomSearch' already exists. Creating a new version of this model...\n",
      "2025/09/28 20:44:56 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Best-logreg-from-RandomSearch, version 2\n",
      "Created version '2' of model 'Best-logreg-from-RandomSearch'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the best model on the test set...\n",
      "Logging final test metrics...\n",
      "üèÉ View run Randomized Hyperparameter Search at: http://localhost:5002/#/experiments/2/runs/3f1c16345ba546189b1cdeca15dcb899\n",
      "üß™ View experiment at: http://localhost:5002/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "from scipy.stats import loguniform, uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load files\n",
    "X_train = np.loadtxt(\"src/data/X_train.csv\", delimiter=\",\")\n",
    "X_test = np.loadtxt(\"src/data/X_test.csv\", delimiter=\",\")\n",
    "y_train = np.loadtxt(\"src/data/y_train.csv\", delimiter=\",\")\n",
    "y_test = np.loadtxt(\"src/data/y_test.csv\", delimiter=\",\")\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"load model on cloud #1\")\n",
    "\n",
    "# from create_trained_model import train_and_log_model\n",
    "\n",
    "# train_and_log_model(n_iter = 50, random_state = 44)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Randomized Hyperparameter Search\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(solver='saga', penalty='elasticnet'))\n",
    "            ])\n",
    "    \n",
    "    param_distributions = {\n",
    "            'classifier__C': loguniform(1e-5, 100),\n",
    "            'classifier__l1_ratio': uniform(0, 1),\n",
    "            'classifier__max_iter': np.arange(100, 1000, 100)\n",
    "        }\n",
    "    mlflow.log_params({\n",
    "            \"search_space_C\": f\"loguniform({1e-5}, {100})\",\n",
    "            \"search_space_l1_ratio\": f\"uniform(0, 1)\",\n",
    "            \"search_space_max_iter\": f\"arange(100, 1000, 100)\"\n",
    "        })\n",
    "    \n",
    "    # to create A/B testing\n",
    "    n_iter = 2\n",
    "    random_state = 44\n",
    "    mlflow.log_params({\n",
    "            \"n_iter\": n_iter,\n",
    "            \"random_state\": random_state,\n",
    "        })\n",
    "    \n",
    "    print(f\"Running RandomizedSearchCV with n_iter={n_iter}...\")\n",
    "    random_search = RandomizedSearchCV( estimator=pipeline,\n",
    "                                        param_distributions=param_distributions,\n",
    "                                        n_iter=n_iter,\n",
    "                                        cv=8,  # 8-fold cross-validation\n",
    "                                        scoring='roc_auc',  # Use ROC AUC score for evaluation\n",
    "                                        random_state=random_state,\n",
    "                                        n_jobs=-1,  # Use all available CPU cores\n",
    "                                        )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # --- 4. Log Best Results to MLflow ---\n",
    "    # Get the best parameters and score from the search\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    best_estimator = random_search.best_estimator_\n",
    "\n",
    "    # MLflow will log these as a single set of parameters for this run.\n",
    "    print(\"Logging best parameters and cross-validation score...\")\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"best_cv_roc_auc\", best_score)\n",
    "\n",
    "    # Log the best estimator's details\n",
    "    print(\"Logging best estimator model...\")\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=best_estimator,\n",
    "        name=\"Best_model\",\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"Best-logreg-from-RandomSearch\", # mandatory if wants to save model as .pkl\n",
    "    )\n",
    "    mlflow.set_logged_model_tags(\n",
    "        model_info.model_id, {\"Training Info\": \"model for A/B testing\",\n",
    "                              \"random_state\":random_state}\n",
    "    )\n",
    "    base_model_uri = mlflow.get_artifact_uri(\"Best_model\")\n",
    "    # --- 5. Evaluate the Best Model on the Test Set ---\n",
    "    print(\"Evaluating the best model on the test set...\")\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "    y_pred_proba = best_estimator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Log final metrics on the test set\n",
    "    print(\"Logging final test metrics...\")\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c23c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 20:45:37 INFO mlflow.tracking.fluent: Experiment with name 'load model on cloud #2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV with n_iter=2...\n",
      "Logging best parameters and cross-validation score...\n",
      "Creature signature for model...\n",
      "Logging best estimator model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Best-logreg-from-RandomSearch' already exists. Creating a new version of this model...\n",
      "2025/09/28 20:45:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Best-logreg-from-RandomSearch, version 3\n",
      "Created version '3' of model 'Best-logreg-from-RandomSearch'.\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 14.30it/s]\n",
      "2025/09/28 20:45:45 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-7946d37476964a01bbcb0d6b984249d8\n",
      "2025/09/28 20:45:45 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n",
      "2025/09/28 20:45:45 WARNING mlflow.models.evaluation.evaluators.classifier: According to the evaluation dataset label values, the model type looks like None, but you specified model type 'classifier'. Please verify that you set the `model_type` and `dataset` arguments correctly.\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "2025/09/28 20:45:46 INFO mlflow.models.evaluation.evaluators.classifier: The evaluation dataset is inferred as binary dataset, positive label is 1.0, negative label is 0.0.\n",
      "/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "2025/09/28 20:45:46 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2025/09/28 20:45:47 WARNING mlflow.models.evaluation.evaluators.shap: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging final test metrics...\n",
      "üèÉ View run Randomized Hyperparameter Search at: http://localhost:5002/#/experiments/3/runs/da5ac2607b294d9c910df48854c4c48a\n",
      "üß™ View experiment at: http://localhost:5002/#/experiments/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1050x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from scipy.stats import loguniform, uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# decide about the model named used to recover model uri\n",
    "model_name = \"Best_model_rs_1\"\n",
    "n_iter=2\n",
    "random_state=1\n",
    "\n",
    "# Load files\n",
    "X_train = np.loadtxt(\"src/data/X_train.csv\", delimiter=\",\")\n",
    "X_test = np.loadtxt(\"src/data/X_test.csv\", delimiter=\",\")\n",
    "y_train = np.loadtxt(\"src/data/y_train.csv\", delimiter=\",\")\n",
    "y_test = np.loadtxt(\"src/data/y_test.csv\", delimiter=\",\")\n",
    "\n",
    "# evaluation with mlflow\n",
    "from sklearn import datasets\n",
    "d = datasets.load_breast_cancer()\n",
    "eval_data = X_test.copy()\n",
    "eval_data = pd.DataFrame(eval_data, columns=d.feature_names)\n",
    "eval_data[\"label\"] = y_test\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"load model on cloud #2\")\n",
    "\n",
    "# from create_trained_model import train_and_log_model\n",
    "# train_and_log_model(n_iter = 50, random_state = 44)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Randomized Hyperparameter Search\"):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(solver='saga', penalty='elasticnet'))\n",
    "            ])\n",
    "    \n",
    "    param_distributions = {\n",
    "            'classifier__C': loguniform(1e-5, 100),\n",
    "            'classifier__l1_ratio': uniform(0, 1),\n",
    "            'classifier__max_iter': np.arange(100, 1000, 100)\n",
    "        }\n",
    "    \n",
    "    print(f\"Running RandomizedSearchCV with n_iter={n_iter}...\")\n",
    "    random_search = RandomizedSearchCV( estimator=pipeline,\n",
    "                                        param_distributions=param_distributions,\n",
    "                                        n_iter=n_iter,\n",
    "                                        cv=8,  # 8-fold cross-validation\n",
    "                                        scoring='roc_auc',  # Use ROC AUC score for evaluation\n",
    "                                        random_state=random_state,\n",
    "                                        n_jobs=-1,  # Use all available CPU cores\n",
    "                                        )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # MLflow will log these as a single set of parameters for this run.\n",
    "    print(\"Logging best parameters and cross-validation score...\")\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"best_cv_roc_auc\", best_score)\n",
    "\n",
    "    # Infer signature\n",
    "    print(\"Creature signature for model...\")\n",
    "    from mlflow.models import infer_signature\n",
    "    signature = infer_signature(X_test, random_search.best_estimator_.predict(X_test))\n",
    "    # Log the best estimator's details\n",
    "    print(\"Logging best estimator model...\")\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=best_estimator,\n",
    "        name=f\"{model_name}\",\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"Best-logreg-from-RandomSearch\", # mandatory if wants to save model as .pkl\n",
    "        tags={\"Training Info\": \"model for A/B testing\",\n",
    "                              \"random_state\":random_state},\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    model_uri = mlflow.get_artifact_uri(f\"{model_name}\")\n",
    "        \n",
    "    # --- 5. Evaluate the Best Model on the Test Set ---\n",
    "    # Comprehensive evaluation with MLflow\n",
    "    result = mlflow.evaluate(\n",
    "        model_info.model_uri,\n",
    "        eval_data,\n",
    "        targets=\"label\",\n",
    "        model_type=\"classifier\", \n",
    "        evaluators=[\"default\"],\n",
    "    )\n",
    "\n",
    "    # Log final metrics on the test set\n",
    "    print(\"Logging final test metrics...\")\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e2e323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow-artifacts:/3/da5ac2607b294d9c910df48854c4c48a/artifacts/Best_model_rs_1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04204a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [02:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricThreshold\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# First, evaluate your scikit-learn model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define quality thresholds for classification models\u001b[39;00m\n\u001b[1;32m      7\u001b[0m quality_thresholds \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: MetricThreshold(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: MetricThreshold(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.80\u001b[39m, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m: MetricThreshold(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     11\u001b[0m }\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/models/evaluation/deprecated.py:23\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_databricks_uri(tracking_uri):\n\u001b[1;32m     13\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `mlflow.evaluate` API has been deprecated as of MLflow 3.0.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use these new alternatives:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m     )\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/models/evaluation/base.py:1693\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data, model_type, targets, predictions, dataset_path, feature_names, evaluators, evaluator_config, extra_metrics, custom_artifacts, env_manager, model_config, inference_params, model_id, _called_from_genai_evaluate)\u001b[0m\n\u001b[1;32m   1691\u001b[0m         model \u001b[38;5;241m=\u001b[39m _get_model_from_deployment_endpoint_uri(model, inference_params)\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1693\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_model_or_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m env_manager \u001b[38;5;241m!=\u001b[39m _EnvManager\u001b[38;5;241m.\u001b[39mLOCAL:\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m   1696\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model argument must be a string URI referring to an MLflow model when a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1697\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-local env_manager is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1698\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m   1699\u001b[0m     )\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1280\u001b[0m, in \u001b[0;36m_load_model_or_server\u001b[0;34m(model_uri, env_manager, model_config)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyfunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscoring_server\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   1275\u001b[0m     ScoringServerClient,\n\u001b[1;32m   1276\u001b[0m     StdinScoringServerClient,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env_manager \u001b[38;5;241m==\u001b[39m _EnvManager\u001b[38;5;241m.\u001b[39mLOCAL:\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1282\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting model server for model environment restoration.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1284\u001b[0m local_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(artifact_uri\u001b[38;5;241m=\u001b[39mmodel_uri)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/tracing/provider.py:465\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     is_func_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     enable()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1131\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(Entity(job\u001b[38;5;241m=\u001b[39mjob_entity))\n\u001b[1;32m   1129\u001b[0m     lineage_header_info \u001b[38;5;241m=\u001b[39m LineageHeaderInfo(entities\u001b[38;5;241m=\u001b[39mentity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1131\u001b[0m local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineage_header_info\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m   1136\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:124\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path, lineage_header_info, tracking_uri)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    120\u001b[0m             artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[1;32m    121\u001b[0m             dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    122\u001b[0m             lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artifact_uri\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# When a Model ID like string is passed, suggest using 'models:/{artifact_uri}' instead.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py:304\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    302\u001b[0m tracebacks \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ArtifactProgressBar\u001b[38;5;241m.\u001b[39mfiles(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading artifacts\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures)) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m             f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    248\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ML_Flow/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mlflow.models import MetricThreshold\n",
    "\n",
    "# First, evaluate your scikit-learn model\n",
    "result = mlflow.evaluate(model_uri, eval_data, targets=\"label\", model_type=\"classifier\")\n",
    "\n",
    "# Define quality thresholds for classification models\n",
    "quality_thresholds = {\n",
    "    \"accuracy_score\": MetricThreshold(threshold=0.85, greater_is_better=True),\n",
    "    \"f1_score\": MetricThreshold(threshold=0.80, greater_is_better=True),\n",
    "    \"roc_auc\": MetricThreshold(threshold=0.75, greater_is_better=True),\n",
    "}\n",
    "\n",
    "# Validate model meets quality standards\n",
    "try:\n",
    "    mlflow.validate_evaluation_results(\n",
    "        candidate_result=result,\n",
    "        validation_thresholds=quality_thresholds,\n",
    "    )\n",
    "    print(\"‚úÖ Scikit-learn model meets all quality thresholds\")\n",
    "except mlflow.exceptions.ModelValidationFailedException as e:\n",
    "    print(f\"‚ùå Model failed validation: {e}\")\n",
    "\n",
    "# Compare against baseline model (e.g., previous model version)\n",
    "baseline_result = mlflow.evaluate(\n",
    "    base_model_uri, eval_data, targets=\"label\", model_type=\"classifier\"\n",
    ")\n",
    "\n",
    "# Validate improvement over baseline\n",
    "improvement_thresholds = {\n",
    "    \"f1_score\": MetricThreshold(\n",
    "        threshold=0.02, greater_is_better=True  # Must be 2% better\n",
    "    ),\n",
    "}\n",
    "\n",
    "try:\n",
    "    mlflow.validate_evaluation_results(\n",
    "        candidate_result=result,\n",
    "        baseline_result=baseline_result,\n",
    "        validation_thresholds=improvement_thresholds,\n",
    "    )\n",
    "    print(\"‚úÖ New model improves over baseline\")\n",
    "except mlflow.exceptions.ModelValidationFailedException as e:\n",
    "    print(f\"‚ùå Model doesn't improve sufficiently: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d0841",
   "metadata": {},
   "source": [
    "# DEBUGGING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520155ba",
   "metadata": {},
   "source": [
    "## debug minio access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3f5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.getenv('MIMICK_S3_USER')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.getenv('MIMICK_S3_PASSWORD')\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'  # MinIO default\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://172.19.0.2:9000\"  # Typical MinIO endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "617a6979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 connection successful\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "try:\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.head_bucket(Bucket='s3mimick')\n",
    "    print(\"S3 connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"S3 connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e06ecb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current environment variables:\n",
      "AWS_ACCESS_KEY_ID: minio_user\n",
      "AWS_SECRET_ACCESS_KEY: minio_password\n",
      "MLFLOW_S3_ENDPOINT_URL: http://172.19.0.2:9000\n",
      "MIMICK_S3_USER: minio_user\n",
      "MIMICK_S3_PASSWORD: minio_password\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current environment variables:\")\n",
    "print(f\"AWS_ACCESS_KEY_ID: {os.environ.get('AWS_ACCESS_KEY_ID', 'NOT SET')}\")\n",
    "print(f\"AWS_SECRET_ACCESS_KEY: {os.environ.get('AWS_SECRET_ACCESS_KEY', 'NOT SET')}\")\n",
    "print(f\"MLFLOW_S3_ENDPOINT_URL: {os.environ.get('MLFLOW_S3_ENDPOINT_URL', 'NOT SET')}\")\n",
    "\n",
    "# Check what your Docker environment variables are\n",
    "print(f\"MIMICK_S3_USER: {os.environ.get('MIMICK_S3_USER', 'NOT SET')}\")\n",
    "print(f\"MIMICK_S3_PASSWORD: {os.environ.get('MIMICK_S3_PASSWORD', 'NOT SET')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f875e8e",
   "metadata": {},
   "source": [
    "## debug credential connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce420b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Docker containers:\n",
      "NAME                                IMAGE             COMMAND                  SERVICE    CREATED       STATUS                 PORTS\n",
      "end-to-end-ml-pipeline-minio-1      minio/minio       \"/usr/bin/docker-ent‚Ä¶\"   minio      3 hours ago   Up 3 hours (healthy)   0.0.0.0:9000-9001->9000-9001/tcp, [::]:9000-9001->9000-9001/tcp\n",
      "end-to-end-ml-pipeline-postgres-1   postgres:latest   \"docker-entrypoint.s‚Ä¶\"   postgres   3 hours ago   Up 3 hours             0.0.0.0:5432->5432/tcp, [::]:5432->5432/tcp\n",
      "\n",
      "Checking container logs for bucket creation:\n",
      "minio-create-s3_mimick-1  | Added `minio` successfully.\n",
      "minio-create-s3_mimick-1  | mc: <ERROR> Unable to list folder. Bucket `staging-models` does not exist.\n",
      "minio-create-s3_mimick-1  | Bucket created successfully `minio/staging-models`.\n",
      "minio-create-s3_mimick-1  | Bucket created successfully `minio/production-models`.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# verify the container is up and running\n",
    "echo \"Checking Docker containers:\"\n",
    "docker compose -f compose_mimick_S3.yaml ps\n",
    "\n",
    "echo -e \"\\nChecking container logs for bucket creation:\"\n",
    "docker compose -f compose_mimick_S3.yaml logs minio-create-s3_mimick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e28a86",
   "metadata": {},
   "source": [
    "verify connection can be made to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "664cec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 connection failed: Connect timeout on endpoint URL: \"http://172.19.0.2:9000/\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connection.py\", line 199, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/httpsession.py\", line 465, in send\n",
      "    urllib_response = conn.urlopen(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/util/retry.py\", line 449, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/util/util.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 495, in _make_request\n",
      "    conn.request(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/awsrequest.py\", line 96, in request\n",
      "    rval = super().request(method, url, body, headers, *args, **kwargs)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connection.py\", line 441, in request\n",
      "    self.endheaders()\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/awsrequest.py\", line 123, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/awsrequest.py\", line 223, in send\n",
      "    return super().send(str)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connection.py\", line 279, in connect\n",
      "    self.sock = self._new_conn()\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/urllib3/connection.py\", line 208, in _new_conn\n",
      "    raise ConnectTimeoutError(\n",
      "urllib3.exceptions.ConnectTimeoutError: (<botocore.awsrequest.AWSHTTPConnection object at 0x181a51f30>, 'Connection to 172.19.0.2 timed out. (connect timeout=60)')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/dv/gzhyqctn53s9bh23g7tbvl940000gn/T/ipykernel_59845/2308608061.py\", line 19, in <module>\n",
      "    response = s3.list_buckets()\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/client.py\", line 1060, in _make_api_call\n",
      "    http, parsed_response = self._make_request(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/client.py\", line 1084, in _make_request\n",
      "    return self._endpoint.make_request(operation_model, request_dict)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/endpoint.py\", line 119, in make_request\n",
      "    return self._send_request(request_dict, operation_model)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/endpoint.py\", line 200, in _send_request\n",
      "    while self._needs_retry(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/endpoint.py\", line 360, in _needs_retry\n",
      "    responses = self._event_emitter.emit(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/hooks.py\", line 412, in emit\n",
      "    return self._emitter.emit(aliased_event_name, **kwargs)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/hooks.py\", line 256, in emit\n",
      "    return self._emit(event_name, kwargs)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/hooks.py\", line 239, in _emit\n",
      "    response = handler(**kwargs)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/retryhandler.py\", line 207, in __call__\n",
      "    if self._checker(**checker_kwargs):\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/retryhandler.py\", line 284, in __call__\n",
      "    should_retry = self._should_retry(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/retryhandler.py\", line 320, in _should_retry\n",
      "    return self._checker(attempt_number, response, caught_exception)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/retryhandler.py\", line 363, in __call__\n",
      "    checker_response = checker(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/retryhandler.py\", line 247, in __call__\n",
      "    return self._check_caught_exception(\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/retryhandler.py\", line 416, in _check_caught_exception\n",
      "    raise caught_exception\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/endpoint.py\", line 279, in _do_get_response\n",
      "    http_response = self._send(request)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/endpoint.py\", line 383, in _send\n",
      "    return self.http_session.send(request)\n",
      "  File \"/Applications/anaconda3/envs/ML_Flow/lib/python3.10/site-packages/botocore/httpsession.py\", line 500, in send\n",
      "    raise ConnectTimeoutError(endpoint_url=request.url, error=e)\n",
      "botocore.exceptions.ConnectTimeoutError: Connect timeout on endpoint URL: \"http://172.19.0.2:9000/\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "try:\n",
    "    # Create S3 client with MinIO endpoint\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=os.environ.get('MLFLOW_S3_ENDPOINT_URL'),\n",
    "        aws_access_key_id=os.environ.get('MIMICK_S3_USER'),\n",
    "        aws_secret_access_key=os.environ.get('MIMICK_S3_PASSWORD'),\n",
    "        config=Config(signature_version='s3v4'),\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    response = s3.list_buckets()\n",
    "    print(\"S3 connection successful!\")\n",
    "    print(\"Available buckets:\", [bucket['Name'] for bucket in response['Buckets']])\n",
    "    \n",
    "    # Test specific bucket\n",
    "    s3.head_bucket(Bucket='s3mimick')\n",
    "    print(\"Bucket 's3mimick' is accessible!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"S3 connection failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23ae34",
   "metadata": {},
   "source": [
    "## debug environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237d7fd",
   "metadata": {},
   "source": [
    "bash\n",
    "```\n",
    "‚úó conda activate ML_Flow\n",
    "‚úó source .env\n",
    "‚úó docker compose -f compose_mimick_S3.yaml down\n",
    "‚úó mlflow server --backend-store-uri postgresql://${MIMICK_POSTGRES_USER}:${MIMICK_POSTGRES_PASSWORD}@localhost:5432/${MIMICK_POSTGRES_DATABASE} --artifacts-destination ${MIMICK_S3_BUCKET} --host 0.0.0.0 --port 5003\n",
    "```\n",
    "==> unable to locate credentials\n",
    "\n",
    "\n",
    "```\n",
    "‚úó conda activate ML_Flow\n",
    "‚úó export AWS_ACCESS_KEY_ID=minio_user\n",
    "‚úó export AWS_SECRET_ACCESS_KEY=minio_password\n",
    "‚úó source .env\n",
    "‚úó docker compose -f compose_mimick_S3.yaml down\n",
    "‚úó mlflow server --backend-store-uri postgresql://${MIMICK_POSTGRES_USER}:${MIMICK_POSTGRES_PASSWORD}@localhost:5432/${MIMICK_POSTGRES_DATABASE} --artifacts-destination ${MIMICK_S3_BUCKET} --host 0.0.0.0 --port 5003\n",
    "```\n",
    "==> The AWS Access Key Id you provided does not exist in our records.\n",
    "\n",
    "\n",
    "* IN VSCODE TERMINAL, the .env FILE CAN'T BE ACCSESSS BY MLFLOW\n",
    "```\n",
    "‚úó conda activate ML_Flow\n",
    "‚úó docker compose -f compose_mimick_S3.yaml up -d\n",
    "‚úó source .env\n",
    "‚úó mlflow server --backend-store-uri postgresql://${MIMICK_POSTGRES_USER}:${MIMICK_POSTGRES_PASSWORD}@localhost:5432/${MIMICK_POSTGRES_DATABASE} --artifacts-destination ${MIMICK_S3_BUCKET} --host 0.0.0.0 --port 5003\n",
    "```\n",
    "==> no credential\n",
    "* Necessecary to export manually in VSCode terminal (it struggle finding .env path)\n",
    "```\n",
    "‚úó export AWS_ENDPOINT_URL=http://localhost:9000\n",
    "‚úó export AWS_ACCESS_KEY_ID=minio_user\n",
    "‚úó export AWS_SECRET_ACCESS_KEY=minio_password\n",
    "‚úó mlflow server --backend-store-uri postgresql://${MIMICK_POSTGRES_USER}:${MIMICK_POSTGRES_PASSWORD}@localhost:5432/${MIMICK_POSTGRES_DATABASE} --artifacts-destination ${MIMICK_S3_BUCKET} --host 0.0.0.0 --port 5003\n",
    "```\n",
    "==> ok"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
